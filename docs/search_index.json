[
["index.html", "Gaming under lockdown: Steam data 1 Preface 1.1 Analyses and reproducibility 1.2 Raw data 1.3 Reproducibility", " Gaming under lockdown: Steam data Matti Vuorre 2020-10-02 1 Preface We study changes in gaming behavior during COVID-19 using data from Steam. GitHub repository: https://github.com/digital-wellbeing/steam-lockdown Website: https://digital-wellbeing.github.io/steam-lockdown OSF: https://osf.io/ya9jt/ 1.1 Analyses and reproducibility The data analyses are organized into separate R Markdown files for processing, describing, and modelling. The project is organized as a R bookdown project, so you can reproduce all analyses by building the book (e.g. in RStudio click the “Build Book” button). The results are rendered to docs/index.html and can be viewed in a web browser. 1.2 Raw data Is in data-raw/ which can’t yet be pushed online. 1.3 Reproducibility options(width = 120) library(sessioninfo) session_info() ## ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os macOS Catalina 10.15.7 ## system x86_64, darwin17.0 ## ui X11 ## language (EN) ## collate en_GB.UTF-8 ## ctype en_GB.UTF-8 ## tz Europe/London ## date 2020-10-02 ## ## ─ Packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.0.0) ## bookdown 0.20 2020-06-23 [1] CRAN (R 4.0.2) ## cli 2.0.2 2020-02-28 [1] CRAN (R 4.0.0) ## crayon 1.3.4 2017-09-16 [1] CRAN (R 4.0.0) ## digest 0.6.25 2020-02-23 [1] CRAN (R 4.0.0) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.0.0) ## fansi 0.4.1 2020-01-08 [1] CRAN (R 4.0.0) ## glue 1.4.2 2020-08-27 [1] CRAN (R 4.0.2) ## htmltools 0.5.0 2020-06-16 [1] CRAN (R 4.0.1) ## knitr 1.30 2020-09-22 [1] CRAN (R 4.0.2) ## magrittr 1.5 2014-11-22 [1] CRAN (R 4.0.0) ## rlang 0.4.7 2020-07-09 [1] CRAN (R 4.0.2) ## rmarkdown 2.4.0 2020-09-11 [1] Github (cpsievert/rmarkdown@b79fb4d) ## sessioninfo * 1.1.1 2018-11-05 [1] CRAN (R 4.0.0) ## stringi 1.5.3 2020-09-09 [1] CRAN (R 4.0.2) ## stringr 1.4.0 2019-02-10 [1] CRAN (R 4.0.0) ## withr 2.3.0 2020-09-22 [1] CRAN (R 4.0.2) ## xfun 0.18 2020-09-29 [1] CRAN (R 4.0.2) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.0.0) ## ## [1] /Library/Frameworks/R.framework/Versions/4.0/Resources/library "],
["preprocessing.html", "2 Preprocessing 2.1 Read data 2.2 Dates 2.3 Coding 2.4 Save", " 2 Preprocessing 2.1 Read data Read data from app-specific files paths &lt;- list.files(&quot;data-raw/Top 500 Games July 2020/&quot;, full.names = TRUE) COLS &lt;- cols_only( DateTime = &quot;T&quot;, Players = &quot;d&quot; ) dat &lt;- tibble(appid = paths) %&gt;% mutate(data = map(appid, ~read_csv(., col_types = COLS))) %&gt;% mutate(appid = str_remove(basename(paths), &quot;.csv&quot;)) %&gt;% unnest(data) names(dat) &lt;- c(&quot;appid&quot;, &quot;Date&quot;, &quot;Players&quot;) dat$Date &lt;- as.Date(dat$Date) 2.2 Dates Not all games have existed since the dawn of time. There appear to be some data quality issues in early 2015. dat %&gt;% group_by(Date) %&gt;% summarise(Players = sum(Players, na.rm = TRUE)) %&gt;% ggplot(aes(Date, Players)) + geom_line() ## `summarise()` ungrouping output (override with `.groups` argument) dat %&gt;% mutate(year = year(Date)) %&gt;% group_by(year) %&gt;% summarise(prop_missing = sum(is.na(Players))/n()) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 17 x 2 ## year prop_missing ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2004 0.781 ## 2 2005 0.751 ## 3 2006 0.978 ## 4 2007 0.817 ## 5 2008 0.753 ## 6 2009 0.821 ## 7 2010 0.305 ## 8 2011 0.246 ## 9 2012 0.307 ## 10 2013 0.424 ## 11 2014 0.546 ## 12 2015 0.234 ## 13 2016 0.0391 ## 14 2017 0.0388 ## 15 2018 0.0632 ## 16 2019 0.0114 ## 17 2020 0 We only really need 2019 and 2020 dat &lt;- dat %&gt;% filter(Date &gt;= as.Date(&quot;2019-01-01&quot;)) 2.3 Coding Process the hand coded categories titles &lt;- read_excel( &quot;data-raw/500 Steam Games Coding FINAL.xlsx&quot;, col_types = &quot;text&quot; ) names(titles) &lt;- c(&quot;appid&quot;, &quot;Name&quot;, &quot;LB&quot;, &quot;MP&quot;, &quot;COOP&quot;) table(titles$LB) ## ## N0 NN Y0 YY ## 2 404 1 93 titles$LB &lt;- ifelse(titles$LB == &quot;N0&quot;, &quot;NN&quot;, titles$LB) titles$LB &lt;- ifelse(titles$LB == &quot;Y0&quot;, &quot;YY&quot;, titles$LB) table(titles$MP) ## ## NN YY ## 155 345 table(titles$COOP) ## ## NN YY ## 188 312 titles &lt;- titles %&gt;% mutate(across(LB:COOP, ~factor(ifelse(.==&quot;NN&quot;, &quot;No&quot;, &quot;Yes&quot;)))) Look at counts of categories dat &lt;- left_join(titles, dat) ## Joining, by = &quot;appid&quot; dat %&gt;% group_by(LB) %&gt;% summarise( Games = length(unique(appid)), Players = scales::comma(sum(Players, na.rm = TRUE)) ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 3 ## LB Games Players ## &lt;fct&gt; &lt;int&gt; &lt;chr&gt; ## 1 No 406 824,625,371 ## 2 Yes 94 1,482,975,138 dat %&gt;% group_by(MP) %&gt;% summarise( Games = length(unique(appid)), Players = scales::comma(sum(Players, na.rm = TRUE)) ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 3 ## MP Games Players ## &lt;fct&gt; &lt;int&gt; &lt;chr&gt; ## 1 No 155 182,228,172 ## 2 Yes 345 2,125,372,337 dat %&gt;% group_by(COOP) %&gt;% summarise( Games = length(unique(appid)), Players = scales::comma(sum(Players, na.rm = TRUE)) ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 3 ## COOP Games Players ## &lt;fct&gt; &lt;int&gt; &lt;chr&gt; ## 1 No 188 236,904,529 ## 2 Yes 312 2,070,695,980 2.4 Save # Save data to disk dir.create(&quot;data&quot;, showWarnings = FALSE) saveRDS(dat, &quot;data/players.rds&quot;) saveRDS(titles, &quot;data/titles.rds&quot;) "],
["describe-the-data.html", "3 Describe the data 3.1 Features 3.2 Titles 3.3 Total volume", " 3 Describe the data Describe the dataset dat &lt;- read_rds(&quot;data/players.rds&quot;) titles &lt;- read_rds(&quot;data/titles.rds&quot;) dat &lt;- left_join(titles, dat) total &lt;- dat %&gt;% group_by(Date) %&gt;% summarise(Players = sum(Players, na.rm = TRUE)) 3.1 Features Numbers of features titles %&gt;% count(`Loot Boxes` = LB) ## # A tibble: 2 x 2 ## `Loot Boxes` n ## &lt;fct&gt; &lt;int&gt; ## 1 No 406 ## 2 Yes 94 titles %&gt;% count(Multiplayer = MP) ## # A tibble: 2 x 2 ## Multiplayer n ## &lt;fct&gt; &lt;int&gt; ## 1 No 155 ## 2 Yes 345 titles %&gt;% count(COOP) ## # A tibble: 2 x 2 ## COOP n ## &lt;fct&gt; &lt;int&gt; ## 1 No 188 ## 2 Yes 312 titles %&gt;% count(MP, LB) ## # A tibble: 4 x 3 ## MP LB n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 No No 145 ## 2 No Yes 10 ## 3 Yes No 261 ## 4 Yes Yes 84 titles %&gt;% count(Multiplayer = MP, COOP, `Loot Boxes` = LB) %&gt;% arrange(n) %&gt;% mutate(p = scales::percent(n / sum(n), accuracy = 1)) ## # A tibble: 6 x 5 ## Multiplayer COOP `Loot Boxes` n p ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; ## 1 Yes No Yes 6 1% ## 2 No No Yes 10 2% ## 3 Yes No No 27 5% ## 4 Yes Yes Yes 78 16% ## 5 No No No 145 29% ## 6 Yes Yes No 234 47% 3.2 Titles How many titles are there per day dat %&gt;% group_by(Date) %&gt;% summarise(titles = length(unique(appid))) %&gt;% ggplot(aes(Date, titles)) + geom_point() 3.3 Total volume total %&gt;% ggplot(aes(Date, Players)) + geom_line() "],
["gam.html", "4 GAM 4.1 Model totals 4.2 Multiplayer", " 4 GAM # Plotting options theme_set( theme_linedraw() + theme(panel.grid = element_blank()) ) # Modelling options (cores, directory to save model files) ncores &lt;- parallel::detectCores(logical = FALSE) options(mc.cores = ncores, loo.cores = ncores) dir.create(&quot;models&quot;, FALSE) # knitr options opts_chunk$set(echo = TRUE, message = FALSE) GAM dat &lt;- left_join( read_rds(&quot;data/titles.rds&quot;), read_rds(&quot;data/players.rds&quot;) ) # Add useful time indicators cd &lt;- as.Date(&quot;2020-03-11&quot;) dat &lt;- dat %&gt;% mutate( year = factor(year(Date)), ymonth = month(Date, label = FALSE) - 1, yweek = week(Date) - 1, yday = yday(Date) - 1, wday = wday(Date, week_start = 1, label = FALSE) - 1, wend = factor(as.numeric(wday %in% c(5, 6)), labels = c(&quot;No&quot;, &quot;Yes&quot;)) ) # Limit both years to last yday in 2020 dat &lt;- dat %&gt;% filter(yday &lt;= max(yday[year==2020])) group_by(dat, year) %&gt;% summarise(max(Date)) ## # A tibble: 2 x 2 ## year `max(Date)` ## &lt;fct&gt; &lt;date&gt; ## 1 2019 2019-07-15 ## 2 2020 2020-07-14 4.1 Model totals total &lt;- dat %&gt;% group_by(across(c(Date, year:wend))) %&gt;% summarise( Players = sum(Players, na.rm = TRUE), ngames = length(unique(appid)) ) %&gt;% ungroup() years &lt;- total %&gt;% group_by(year) %&gt;% nest() 4.1.1 mgcv years &lt;- years %&gt;% mutate( m0 = map(data, ~gamm( Players ~ t2(yday, k = 27) + t2(wday, k = 7), data = .x, method = &quot;REML&quot; )), m1 = map(data, ~gamm( Players ~ t2(yday, wday, k = c(27, 7)), data = .x, method = &quot;REML&quot; )) ) anova( years$m0[[2]][[&quot;lme&quot;]], years$m1[[2]][[&quot;lme&quot;]] ) ## Model df AIC BIC logLik Test L.Ratio ## years$m0[[2]][[&quot;lme&quot;]] 1 6 5162.805 5182.381 -2575.403 ## years$m1[[2]][[&quot;lme&quot;]] 2 8 5132.825 5158.884 -2558.412 1 vs 2 33.98069 ## p-value ## years$m0[[2]][[&quot;lme&quot;]] ## years$m1[[2]][[&quot;lme&quot;]] &lt;.0001 summary(years$m1[[2]][[&quot;gam&quot;]]) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Players ~ t2(yday, wday, k = c(27, 7)) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4491388 6047 742.8 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## t2(yday,wday) 57.02 57.02 53.4 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.974 ## Scale est. = 7.1659e+09 n = 196 acf(residuals(years$m1[[2]][[&quot;gam&quot;]])) gam.check(years$m1[[2]][[&quot;gam&quot;]]) ## ## &#39;gamm&#39; based fit - care required with interpretation. ## Checks based on working residuals may be misleading. ## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may ## indicate that k is too low, especially if edf is close to k&#39;. ## ## k&#39; edf k-index p-value ## t2(yday,wday) 188 57 1.17 1 vis.gam(years$m1[[1]][[&quot;gam&quot;]], theta = 30, phi = 10) Figure # Prediction dataframe tmp &lt;- years %&gt;% mutate( preds = map(m1, ~as.data.frame(predict(.x[[&quot;gam&quot;]], se.fit = TRUE))) ) %&gt;% unnest(c(data, preds)) %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() # Excess players dataframe tmp2 &lt;- tmp %&gt;% select(year, yweek, Players, fit) %&gt;% pivot_wider( names_from = year, values_from = c(Players, fit), values_fn = mean ) %&gt;% mutate(excess_empirical = Players_2020 - Players_2019) %&gt;% mutate(excess_model = fit_2020 - fit_2019) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(year, yweek, starts_with(&quot;excess&quot;)) # left_join(select(tmp, year, Date, yweek)) # Predictions and data figure p1 &lt;- tmp %&gt;% ggplot(aes(Date, Players, alpha = year, group = year)) + # scale_x_date() + geom_vline(xintercept = cd, size = .1) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + scale_y_continuous( breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_ribbon( aes(ymin = fit-se.fit*2, ymax = fit+se.fit*2), alpha=.1 ) + geom_line(aes(y=fit), size = .2) + geom_point(shape = 1, size = 1, fill = &quot;white&quot;) p1 # Excess gaming figure p2 &lt;- tmp2 %&gt;% ggplot(aes(x = yweek, alpha = NA)) + # Week of WHO announcement geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + geom_line(aes(y = excess_model), size = .2) + geom_point( aes(y = excess_empirical), shape = 1, size = 1, fill = &quot;white&quot; ) + geom_hline(yintercept = 0, lty = 2, size = .1) + scale_y_continuous( &quot;Excess players\\n(2020 - 2019)&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) p2 ## Warning: Using alpha for a discrete variable is not advised. (p1 + theme(axis.title.x = element_blank())) / p2 + plot_layout(heights = c(.75, .25), guides = &quot;collect&quot;) ## Warning: Using alpha for a discrete variable is not advised. ggsave(&quot;Figure1-mgcv.png&quot;, width = 8, height = 5) ## Warning: Using alpha for a discrete variable is not advised. Weekend effect figure years %&gt;% mutate(preds = map(m1, ~as.data.frame(predict(.x[[&quot;gam&quot;]], se.fit = TRUE)))) %&gt;% unnest(c(data, preds)) %&gt;% group_by(year, yweek) %&gt;% summarise( w_eff = mean(Players[wday %in% 5:6]) - mean(Players[wday %in% 0:4]), fit = mean(fit[wday %in% 5:6]) - mean(fit[wday %in% 0:4]), ) %&gt;% mutate(year = factor(year)) %&gt;% ggplot(aes(yweek, w_eff, alpha = year, group = year)) + scale_x_continuous( &quot;Week number&quot;, breaks = pretty_breaks() ) + scale_y_continuous( breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_line(aes(y=fit)) + geom_point() # show it for weeks 5, 15, and 25 years %&gt;% mutate(preds = map(m1, ~as.data.frame(predict(.x[[&quot;gam&quot;]], se.fit = TRUE)))) %&gt;% unnest(c(data, preds)) %&gt;% filter(yweek %in% c(5, 15, 25)) %&gt;% # group_by(year, yweek, yday) %&gt;% mutate(year = factor(year)) %&gt;% ggplot(aes(wday, Players)) + geom_point() + geom_line(aes(y = fit)) + facet_grid(year~yweek) 4.1.2 brms sampler_0 &lt;- brm( Players ~ t2(yday, k = 27) + t2(wday, k = 7), # prior = prior(normal(4.5e6, 5e5), class = &quot;Intercept&quot;), data = filter(total, year==2020), chains = 0, file = &quot;models/brm-sampler-0&quot; ) sampler_1 &lt;- brm( Players ~ t2(yday, wday, k = c(27, 7)), # prior = prior(normal(4.5e6, 1e5), class = &quot;Intercept&quot;), data = filter(total, year==2020), chains = 0, file = &quot;models/brm-sampler-1&quot; ) sampler_2 &lt;- brm( Players ~ t2(yday, wday, k = c(27, 7)) + ar(time = yday, p = 1), # prior = prior(normal(4.5e6, 1e5), class = &quot;Intercept&quot;), data = filter(total, year==2020), chains = 0, file = &quot;models/brm-sampler-2&quot; ) # This model has a hard time converging so we set inits for the intercept years &lt;- years %&gt;% mutate( bm0 = map2(data, year, ~update( sampler_0, newdata = .x, chains = 4, iter = 4000, inits = function() {list(Intercept = 4.5e6)}, control = list(adapt_delta = .99), file = str_glue(&quot;models/brm-{.y}-m0&quot;) )), bm1 = map2(data, year, ~update( sampler_1, newdata = .x, chains = 4, iter = 4000, inits = function() {list(Intercept = 4.5e6)}, control = list(adapt_delta = .99), file = str_glue(&quot;models/brm-{.y}-m1&quot;) )), bm2 = map2(data, year, ~update( sampler_2, newdata = .x, chains = 4, iter = 4000, inits = function() {list(Intercept = 4.5e6)}, control = list(adapt_delta = .99), file = str_glue(&quot;models/brm-{.y}-m2&quot;) )) ) map(years$bm0, summary) ## [[1]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, k = 27) + t2(wday, k = 7) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sds(t2yday_1) 3140375.41 1931596.04 688118.17 7245725.75 1.01 410 1498 ## sds(t2wday_1) 698957.62 246675.28 366244.83 1312733.38 1.00 1949 3205 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4131476.19 8643.19 4114591.68 4148408.74 1.00 9252 6132 ## t2yday_1 137335.09 9750.69 118022.14 155865.67 1.00 2222 4234 ## t2wday_1 209829.48 8577.12 192847.56 226648.96 1.00 9171 4882 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 118933.33 9617.86 101855.88 138252.44 1.01 599 2491 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ## ## [[2]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, k = 27) + t2(wday, k = 7) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2yday_1) 5933923.97 1009065.17 4237181.33 8237091.24 1.00 1437 ## sds(t2wday_1) 642551.30 242753.01 323810.00 1251140.93 1.00 2150 ## Tail_ESS ## sds(t2yday_1) 2296 ## sds(t2wday_1) 3306 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4485180.91 8477.84 4468364.43 4501760.77 1.00 11132 6134 ## t2yday_1 -73684.26 9055.69 -91925.39 -55772.09 1.00 10429 6521 ## t2wday_1 183460.42 8299.92 167425.26 199806.65 1.00 12741 5561 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 116553.07 6500.28 104534.40 129848.53 1.00 8073 6257 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). gam.vcomp(years$m0[[2]][[&quot;gam&quot;]], rescale = FALSE) # Compare ## t2(yday) t2(wday) ## 6241236.8 572271.5 map(years$bm1, summary) ## [[1]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, wday, k = c(27, 7)) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2ydaywday_1) 215594.09 160732.73 10966.17 613935.53 1.00 3118 ## sds(t2ydaywday_2) 7204025.68 1860116.51 4387471.72 11475105.87 1.00 2447 ## sds(t2ydaywday_3) 4514113.25 2321947.75 2216629.37 8742885.48 1.00 1163 ## Tail_ESS ## sds(t2ydaywday_1) 3242 ## sds(t2ydaywday_2) 4008 ## sds(t2ydaywday_3) 1068 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4132036.59 8570.93 4114941.77 4148743.71 1.00 10695 4926 ## t2ydaywday_1 205090.46 8417.92 188912.33 221417.15 1.00 13259 5615 ## t2ydaywday_2 -130363.57 8650.15 -147152.68 -113497.56 1.00 9735 5780 ## t2ydaywday_3 42352.34 8706.46 25321.94 59220.76 1.00 11427 6096 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 116569.17 7491.92 102658.87 131697.39 1.00 2104 1526 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ## ## [[2]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, wday, k = c(27, 7)) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2ydaywday_1) 559894.76 235059.21 140808.47 1101095.34 1.00 2039 ## sds(t2ydaywday_2) 6540650.59 1665083.83 4031383.32 10495088.39 1.00 2246 ## sds(t2ydaywday_3) 28904897.04 3778821.37 22340552.86 37229776.95 1.00 1289 ## Tail_ESS ## sds(t2ydaywday_1) 1957 ## sds(t2ydaywday_2) 3394 ## sds(t2ydaywday_3) 2573 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4485869.84 6444.76 4473136.35 4498590.03 1.00 13886 5987 ## t2ydaywday_1 177276.87 6593.10 164357.20 190136.28 1.00 9544 5744 ## t2ydaywday_2 74333.12 7011.04 60732.48 88125.07 1.00 9869 6174 ## t2ydaywday_3 43303.65 7376.32 28865.14 57713.36 1.00 6988 5815 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 86674.84 5898.27 76036.38 99046.65 1.00 3792 5218 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). map(years$bm2, summary) ## [[1]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, wday, k = c(27, 7)) + ar(time = yday, p = 1) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2ydaywday_1) 178364.82 131989.59 7522.88 499142.17 1.00 2966 ## sds(t2ydaywday_2) 7978386.63 1743393.33 5263770.16 12184139.14 1.00 1548 ## sds(t2ydaywday_3) 844954.99 538037.73 105225.67 2172772.92 1.00 1336 ## Tail_ESS ## sds(t2ydaywday_1) 3707 ## sds(t2ydaywday_2) 3071 ## sds(t2ydaywday_3) 2218 ## ## Correlation Structures: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## ar[1] 0.79 0.09 0.64 0.98 1.00 1469 1040 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4170243.96 94248.66 4088092.69 4398734.11 1.00 1780 761 ## t2ydaywday_1 203991.02 7453.18 189171.13 218760.86 1.00 9630 6054 ## t2ydaywday_2 -182351.83 67708.61 -361790.84 -106738.92 1.00 1991 1819 ## t2ydaywday_3 40049.02 7570.60 25359.75 54725.30 1.00 7120 6084 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 96083.71 5417.89 86102.29 107405.21 1.00 4183 5190 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ## ## [[2]] ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, wday, k = c(27, 7)) + ar(time = yday, p = 1) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2ydaywday_1) 522266.78 224319.32 120551.33 1018342.66 1.00 2170 ## sds(t2ydaywday_2) 6897256.71 1623665.15 4424409.11 10543378.73 1.00 2608 ## sds(t2ydaywday_3) 645611.57 409913.36 40178.70 1614495.05 1.00 2589 ## Tail_ESS ## sds(t2ydaywday_1) 1878 ## sds(t2ydaywday_2) 3914 ## sds(t2ydaywday_3) 2349 ## ## Correlation Structures: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## ar[1] 0.98 0.02 0.95 1.01 1.00 4148 5574 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4460016.96 370265.05 3718170.05 5231356.80 1.00 1477 1158 ## t2ydaywday_1 178746.71 8163.91 162417.60 194251.11 1.00 13462 6239 ## t2ydaywday_2 -41314.31 223588.54 -490180.26 429033.04 1.00 1556 1214 ## t2ydaywday_3 46970.56 8355.87 30582.92 63518.83 1.00 10271 6705 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 113139.79 6443.98 101533.87 126729.09 1.00 7651 6018 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). gam.vcomp(years$m1[[2]][[&quot;gam&quot;]], rescale = FALSE) # Compare ## t2(yday,wday)rr t2(yday,wday)nr t2(yday,wday)rn ## 570590.4 7319951.8 30036034.6 cbind(years$bm1[[2]][[&quot;data&quot;]], fitted(years$bm1[[2]])) %&gt;% ggplot(aes(yday, Players)) + geom_point() + geom_line(aes(y = Estimate)) acf(residuals(years$bm1[[2]])[,1]) summary(years$bm1[[2]]) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Players ~ t2(yday, wday, k = c(27, 7)) ## Data: .x (Number of observations: 196) ## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1; ## total post-warmup samples = 8000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(t2ydaywday_1) 559894.76 235059.21 140808.47 1101095.34 1.00 2039 ## sds(t2ydaywday_2) 6540650.59 1665083.83 4031383.32 10495088.39 1.00 2246 ## sds(t2ydaywday_3) 28904897.04 3778821.37 22340552.86 37229776.95 1.00 1289 ## Tail_ESS ## sds(t2ydaywday_1) 1957 ## sds(t2ydaywday_2) 3394 ## sds(t2ydaywday_3) 2573 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4485869.84 6444.76 4473136.35 4498590.03 1.00 13886 5987 ## t2ydaywday_1 177276.87 6593.10 164357.20 190136.28 1.00 9544 5744 ## t2ydaywday_2 74333.12 7011.04 60732.48 88125.07 1.00 9869 6174 ## t2ydaywday_3 43303.65 7376.32 28865.14 57713.36 1.00 6988 5815 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 86674.84 5898.27 76036.38 99046.65 1.00 3792 5218 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). bayes_R2(years$bm1[[2]]) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.9732051 0.002436581 0.9679154 0.9773106 # Compare mgcv and brms years %&gt;% mutate( pred_b = map(bm1, ~as.data.frame(fitted(.))), pred_m = map(m1, ~fitted(.[[&quot;gam&quot;]])) ) %&gt;% select(year, data, starts_with(&quot;pred&quot;)) %&gt;% unnest(c(data, pred_m, pred_b)) %&gt;% pivot_longer(c(Estimate, pred_m)) %&gt;% ggplot(aes(Date, Players)) + geom_point() + geom_line(aes(y = value, col = name)) + facet_wrap(&quot;year&quot;, scales = &quot;free&quot;, nrow = 2) 4.1.2.1 Figure # Prediction dataframe tmp &lt;- years %&gt;% mutate( p = map2(data, bm1, ~add_fitted_draws(.x, .y)) ) %&gt;% select(year, p) %&gt;% unnest(p) # Data with same dates for years for visualizing xtmp &lt;- total %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() # Predictions and data figure p1 &lt;- tmp %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() %&gt;% group_by(year, Date) %&gt;% mean_qi(.value) %&gt;% ungroup() %&gt;% ggplot(aes(Date, .value, alpha = year, group = year)) + # scale_x_date() + geom_vline(xintercept = cd, size = .1) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + scale_y_continuous( &quot;Players&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_ribbon( aes(ymin = .lower, ymax = .upper), alpha=.1 ) + geom_line(size = .2) + geom_point( data = xtmp, aes(y=Players), shape = 1, size = 1, fill = &quot;white&quot; ) p1 # Excess players dataframe tmp2 &lt;- tmp %&gt;% group_by(year, yweek, .draw) %&gt;% summarise(week_mean = mean(.value)) %&gt;% mutate(.draw = 1:n()) %&gt;% ungroup() %&gt;% pivot_wider( names_from = year, values_from = c(week_mean) ) %&gt;% mutate(excess_model = `2020` / `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(year, yweek, starts_with(&quot;excess&quot;)) tmp3 &lt;- xtmp %&gt;% group_by(year, yweek) %&gt;% summarise(week_mean = mean(Players)) %&gt;% pivot_wider( names_from = year, values_from = c(week_mean) ) %&gt;% mutate(excess_data = `2020` / `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(year, yweek, starts_with(&quot;excess&quot;)) # left_join(select(tmp, year, Date, yweek)) # Excess gaming figure p2 &lt;- tmp2 %&gt;% group_by(year, yweek) %&gt;% mean_qi(excess_model) %&gt;% ggplot(aes(x = yweek, alpha = NA)) + # Week of WHO announcement geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .2) + geom_line(aes(y = excess_model), size = .2) + geom_point( data = tmp3, aes(y = excess_data), shape = 1, size = 1, fill = &quot;white&quot; ) + # geom_hline(yintercept = 0, lty = 2, size = .1) + scale_y_continuous( &quot;Excess players in 2020&quot;, breaks = pretty_breaks(), labels = scales::percent ) p2 ## Warning: Using alpha for a discrete variable is not advised. (p1 + theme(axis.title.x = element_blank())) / p2 + plot_layout(heights = c(.75, .25), guides = &quot;collect&quot;) ## Warning: Using alpha for a discrete variable is not advised. ggsave(&quot;Figure1-brms.png&quot;, width = 8, height = 5) ## Warning: Using alpha for a discrete variable is not advised. 4.1.2.2 Weekend effect tmp &lt;- years %&gt;% mutate(data2 = map(data, ~filter(., yweek %in% c(5, 15, 25)))) %&gt;% mutate(p = map2(data2, bm1, ~add_fitted_draws(.x, .y))) %&gt;% select(year, p) %&gt;% unnest(p) %&gt;% mutate(year = factor(year)) %&gt;% mutate(yweek = fct_inorder(str_glue(&quot;Week {yweek}&quot;))) p1 &lt;- tmp %&gt;% mutate(wday = wday(Date, label = TRUE, week_start = 1)) %&gt;% group_by(year, yweek, wday, Players) %&gt;% mean_qi(.value) %&gt;% ggplot(aes(wday, alpha = year, group = year)) + scale_y_continuous( &quot;Players&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_point(aes(y = Players), shape = 1, size = 1, fill = &quot;white&quot;) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .1) + geom_line(aes(y = .value)) + facet_grid(~yweek) weffs_data &lt;- total %&gt;% select(year, yweek, wday, Players) %&gt;% pivot_wider(names_from = wday, values_from = Players) %&gt;% mutate( Weekend_effect = rowMeans(select(., `5`, `6`)) / rowMeans(select(., `0`, `1`, `2`, `3`, `4`)), ) %&gt;% mutate(year = factor(year)) weffs &lt;- years %&gt;% mutate(p = map2(data, bm1, ~add_fitted_draws(.x, .y))) %&gt;% select(year, p) %&gt;% unnest(p) %&gt;% select(year, yweek, wday, .draw, .value) %&gt;% pivot_wider(names_from = wday, values_from = c(.value)) %&gt;% ungroup() %&gt;% mutate( Weekend_effect = rowMeans(select(., `5`, `6`)) / rowMeans(select(., `0`, `1`, `2`, `3`, `4`)), ) p2 &lt;- weffs %&gt;% mutate(year = factor(year)) %&gt;% group_by(year, yweek) %&gt;% mean_qi(Weekend_effect) %&gt;% ggplot(aes(yweek, Weekend_effect, alpha = year, group = year)) + geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + scale_y_continuous( &quot;Weekend effect&quot;, breaks = pretty_breaks(), labels = scales::percent ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_line(size = .5) + geom_ribbon( aes(ymin = .lower, ymax = .upper), alpha = .1 ) + geom_point(data = weffs_data, shape = 1) + theme(legend.position = &quot;none&quot;) # Excess weekend effect dataframe weffs2 &lt;- weffs %&gt;% select(year, yweek, .draw, Weekend_effect) %&gt;% pivot_wider( names_from = year, values_from = c(Weekend_effect) ) %&gt;% mutate(Difference = `2020` - `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(year, yweek, .draw, Difference) p3 &lt;- weffs2 %&gt;% group_by(year, yweek) %&gt;% mean_qi(Difference) %&gt;% ggplot(aes(yweek, Difference)) + geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + scale_y_continuous( &quot;Difference\\n(2020 - 2019)&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_hline(lty = 2, yintercept = 0, size = .2) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .2) + geom_line() + theme(legend.position = &quot;none&quot;) ((p1 + theme(axis.title.x = element_blank())) / p2) + plot_layout(heights = c(.4, .6), guides = &quot;collect&quot;) ggsave(&quot;Figure2-brms.png&quot;, width = 8, height = 5) 4.2 Multiplayer mp &lt;- dat %&gt;% mutate(year = factor(year)) %&gt;% group_by(across(c(MP, Date, year:wend))) %&gt;% summarise( Players = sum(Players, na.rm = TRUE), ngames = length(unique(appid)) ) %&gt;% ungroup() %&gt;% group_by(MP, year) %&gt;% nest() mp ## # A tibble: 4 x 3 ## # Groups: MP, year [4] ## MP year data ## &lt;fct&gt; &lt;fct&gt; &lt;list&gt; ## 1 No 2019 &lt;tibble [196 × 8]&gt; ## 2 No 2020 &lt;tibble [196 × 8]&gt; ## 3 Yes 2019 &lt;tibble [196 × 8]&gt; ## 4 Yes 2020 &lt;tibble [196 × 8]&gt; mp %&gt;% unnest(data) %&gt;% # Make dates same across years for viz group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() %&gt;% ggplot(aes(Date, Players, alpha = year, group = year)) + # scale_x_date() + geom_vline(xintercept = cd, size = .1) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + scale_y_continuous( breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_line(size = .3) + geom_point(shape = 21, size = 1, fill = &quot;white&quot;) + facet_grid(rows = &quot;MP&quot;, scales = &quot;free&quot;) 4.2.1 mgcv mp &lt;- mp %&gt;% mutate( m0 = map(data, ~gamm( Players ~ t2(yday, k = 27) + t2(wday, k = 7), data = .x, method = &quot;REML&quot; )), m1 = map(data, ~gamm( Players ~ t2(yday, wday, k = c(27, 7)), data = .x, method = &quot;REML&quot; )) ) Figure # Prediction dataframe tmp &lt;- mp %&gt;% ungroup() %&gt;% mutate(MP = factor(MP, labels = c(&quot;Single-player&quot;, &quot;Multiplayer&quot;))) %&gt;% mutate( preds = map(m1, ~as.data.frame(predict(.x[[&quot;gam&quot;]], se.fit = TRUE))) ) %&gt;% unnest(c(data, preds)) %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() # Excess players dataframe tmp2 &lt;- tmp %&gt;% select(MP, year, yweek, Players, fit) %&gt;% pivot_wider( names_from = year, values_from = c(Players, fit), values_fn = mean ) %&gt;% mutate(excess_empirical = Players_2020 - Players_2019) %&gt;% mutate(excess_model = fit_2020 - fit_2019) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(MP, year, yweek, starts_with(&quot;excess&quot;)) # Predictions and data figure p1 &lt;- tmp %&gt;% ggplot(aes(Date, Players, alpha = year, group = year)) + # scale_x_date() + geom_vline(xintercept = cd, size = .1) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + scale_y_continuous( breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_ribbon( aes(ymin = fit-se.fit*2, ymax = fit+se.fit*2), alpha=.1 ) + geom_line(aes(y=fit), size = .2) + geom_point(shape = 1, size = 1, fill = &quot;white&quot;) + facet_wrap(&quot;MP&quot;, nrow = 1, scales = &quot;free&quot;) p1 # Excess gaming figure p2 &lt;- tmp2 %&gt;% ggplot(aes(x = yweek, alpha = NA)) + # Week of WHO announcement geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + geom_line(aes(y = excess_model), size = .2) + geom_point( aes(y = excess_empirical), shape = 1, size = 1, fill = &quot;white&quot; ) + geom_hline(yintercept = 0, lty = 2, size = .1) + scale_y_continuous( &quot;Excess players\\n(2020 - 2019)&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + facet_wrap(&quot;MP&quot;, nrow = 1, scales = &quot;free&quot;) p2 ## Warning: Using alpha for a discrete variable is not advised. (p1 + theme(axis.title.x = element_blank())) / p2 + plot_layout(heights = c(.75, .25), guides = &quot;collect&quot;) ## Warning: Using alpha for a discrete variable is not advised. ggsave(&quot;Figure1-mp-mgcv.png&quot;, width = 8, height = 5) ## Warning: Using alpha for a discrete variable is not advised. Weekend effect figure mp %&gt;% mutate(preds = map(m1, ~as.data.frame(predict(.x[[&quot;gam&quot;]], se.fit = TRUE)))) %&gt;% unnest(c(data, preds)) %&gt;% group_by(MP, year, yweek) %&gt;% summarise( w_eff = mean(Players[wday %in% 5:6]) - mean(Players[wday %in% 0:4]), fit = mean(fit[wday %in% 5:6]) - mean(fit[wday %in% 0:4]), ) %&gt;% mutate(year = factor(year)) %&gt;% ggplot(aes(yweek, w_eff, alpha = year, group = year)) + scale_x_continuous( &quot;Week number&quot;, breaks = pretty_breaks() ) + scale_y_continuous( breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_line(aes(y=fit)) + geom_point() + facet_wrap(&quot;MP&quot;, nrow = 1, scales = &quot;free&quot;) 4.2.2 brms sampler_0 &lt;- brm( Players ~ t2(yday, k = 27) + t2(wday, k = 7), data = mp$data[[1]], chains = 0, file = &quot;models/brm-sampler-mp-0&quot; ) sampler_1 &lt;- brm( Players ~ t2(yday, wday, k = c(27, 7)), data = mp$data[[1]], chains = 0, file = &quot;models/brm-sampler-mp-1&quot; ) # This model has a hard time converging so we set inits for the intercept mp$bm0 &lt;- vector(&quot;list&quot;, 4) mp$bm1 &lt;- vector(&quot;list&quot;, 4) for (i in 1:4) { this_data &lt;- mp$data[[i]] mp$bm0[[i]] &lt;- update( sampler_0, newdata = this_data, chains = 4, iter = 3000, inits = function() {list(Intercept = mean(this_data$Players))}, control = list(adapt_delta = .99), file = str_glue(&quot;models/brm-mp-{i}-m0&quot;) ) mp$bm1[[i]] &lt;- update( sampler_1, newdata = this_data, chains = 4, iter = 3000, inits = function() {list(Intercept = mean(this_data$Players))}, control = list(adapt_delta = .99), file = str_glue(&quot;models/brm-mp-{i}-m1&quot;) ) } # Did the inits work? for (i in 1:4) { print(mean(mp$data[[i]][[&quot;Players&quot;]])) print(mp$bm1[[i]][[&quot;fit&quot;]]@inits[[1]][[&quot;Intercept&quot;]]) } ## [1] 314174.4 ## [1] 314174.4 ## [1] 370239.5 ## [1] 370239.5 ## [1] 3810860 ## [1] 3810860 ## [1] 4121149 ## [1] 4121149 4.2.2.1 Figure # Prediction dataframe mp &lt;- mp %&gt;% ungroup() %&gt;% mutate(MP = factor(MP, labels = c(&quot;Single-player&quot;, &quot;Multiplayer&quot;))) tmp &lt;- mp %&gt;% mutate( p = map2(data, bm1, ~add_fitted_draws(.x, .y)) ) %&gt;% select(MP, year, p) %&gt;% unnest(p) # Data with same dates for years for visualizing xtmp &lt;- mp %&gt;% select(MP, year, data) %&gt;% unnest(data) %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() # Predictions and data figure p1 &lt;- tmp %&gt;% mutate(year = factor(year)) %&gt;% # Make dates same for 2019 and 2020 to put on same plot group_by(yday) %&gt;% mutate(Date = last(Date)) %&gt;% ungroup() %&gt;% group_by(MP, year, Date) %&gt;% mean_qi(.value) %&gt;% ungroup() %&gt;% ggplot(aes(Date, .value, alpha = year, group = year)) + # scale_x_date() + geom_vline(xintercept = cd, size = .1) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + scale_y_continuous( &quot;Players&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_ribbon( aes(ymin = .lower, ymax = .upper), alpha=.1 ) + geom_line(size = .2) + geom_point( data = xtmp, aes(y=Players), shape = 1, size = 1, fill = &quot;white&quot; ) + facet_wrap(&quot;MP&quot;, nrow = 1, scales = &quot;free&quot;) # Excess players dataframe tmp2 &lt;- tmp %&gt;% group_by(MP, year, yweek, .draw) %&gt;% summarise(week_mean = mean(.value)) %&gt;% mutate(.draw = 1:n()) %&gt;% ungroup() %&gt;% pivot_wider( names_from = year, values_from = c(week_mean) ) %&gt;% mutate(excess_model = `2020` / `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(MP, year, yweek, starts_with(&quot;excess&quot;)) tmp3 &lt;- xtmp %&gt;% group_by(MP, year, yweek) %&gt;% summarise(week_mean = mean(Players)) %&gt;% pivot_wider( names_from = year, values_from = c(week_mean) ) %&gt;% mutate(excess_data = `2020` / `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(MP, year, yweek, starts_with(&quot;excess&quot;)) # left_join(select(tmp, year, Date, yweek)) # Excess gaming figure p2 &lt;- tmp2 %&gt;% group_by(MP, year, yweek) %&gt;% mean_qi(excess_model) %&gt;% ggplot(aes(x = yweek, alpha = NA)) + # Week of WHO announcement geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .2) + geom_line(aes(y = excess_model), size = .2) + geom_point( data = tmp3, aes(y = excess_data), shape = 1, size = 1, fill = &quot;white&quot; ) + geom_hline(yintercept = 1, lty = 2, size = .1) + scale_y_continuous( &quot;2020 excess&quot;, breaks = pretty_breaks(), labels = scales::percent ) + facet_wrap(&quot;MP&quot;, nrow = 1, scales = &quot;free&quot;) + theme(strip.background = element_blank()) (p1 + theme(axis.title.x = element_blank())) / p2 + plot_layout(heights = c(.75, .25), guides = &quot;collect&quot;) &amp; theme(legend.position = &quot;none&quot;) ## Warning: Using alpha for a discrete variable is not advised. ggsave(&quot;Figure1-mp-brms.png&quot;, width = 8, height = 5) ## Warning: Using alpha for a discrete variable is not advised. 4.2.2.2 Weekend effect tmp &lt;- mp %&gt;% mutate(data2 = map(data, ~filter(., yweek %in% c(5, 15, 25)))) %&gt;% mutate(p = map2(data2, bm1, ~add_fitted_draws(.x, .y))) %&gt;% select(MP, year, p) %&gt;% unnest(p) %&gt;% mutate(year = factor(year)) %&gt;% mutate(yweek = fct_inorder(str_glue(&quot;Week {yweek}&quot;))) p1 &lt;- tmp %&gt;% mutate(wday = wday(Date, label = TRUE, week_start = 1)) %&gt;% group_by(MP, year, yweek, wday, Players) %&gt;% mean_qi(.value) %&gt;% ggplot(aes(wday, alpha = year, group = year)) + scale_y_continuous( &quot;Players&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_point(aes(y = Players), shape = 1, size = 1, fill = &quot;white&quot;) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .1) + geom_line(aes(y = .value)) + facet_grid(MP~yweek, scales = &quot;free&quot;) p1 weffs_data &lt;- mp %&gt;% select(MP, year, data) %&gt;% unnest(data) %&gt;% select(MP, year, yweek, wday, Players) %&gt;% pivot_wider(names_from = wday, values_from = Players) %&gt;% mutate( Weekend_effect = rowMeans(select(., `5`, `6`)) / rowMeans(select(., `0`, `1`, `2`, `3`, `4`)), ) %&gt;% mutate(year = factor(year)) weffs &lt;- mp %&gt;% mutate(p = map2(data, bm1, ~add_fitted_draws(.x, .y))) %&gt;% select(MP, year, p) %&gt;% unnest(p) %&gt;% select(MP, year, yweek, wday, .draw, .value) %&gt;% pivot_wider(names_from = wday, values_from = c(.value)) %&gt;% ungroup() %&gt;% mutate( Weekend_effect = rowMeans(select(., `5`, `6`)) / rowMeans(select(., `0`, `1`, `2`, `3`, `4`)), ) p2 &lt;- weffs %&gt;% mutate(year = factor(year)) %&gt;% group_by(MP, year, yweek) %&gt;% mean_qi(Weekend_effect) %&gt;% ggplot(aes(yweek, Weekend_effect, alpha = year, group = year)) + geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + scale_y_continuous( &quot;Weekend effect&quot;, breaks = pretty_breaks(), labels = percent_format(accuracy = 1) ) + scale_alpha_manual(&quot;Year&quot;, values = c(.3, 1)) + geom_line(size = .5) + geom_ribbon( aes(ymin = .lower, ymax = .upper), alpha = .1 ) + geom_point(data = weffs_data, shape = 1) + theme(legend.position = &quot;none&quot;) + facet_grid(rows = &quot;MP&quot;, scales = &quot;free&quot;) # Excess weekend effect dataframe weffs2 &lt;- weffs %&gt;% select(MP, year, yweek, .draw, Weekend_effect) %&gt;% pivot_wider( names_from = year, values_from = c(Weekend_effect) ) %&gt;% mutate(Difference = `2020` - `2019`) %&gt;% mutate(year = &quot;2020&quot;) %&gt;% select(MP, year, yweek, .draw, Difference) p3 &lt;- weffs2 %&gt;% group_by(MP, year, yweek) %&gt;% mean_qi(Difference) %&gt;% ggplot(aes(yweek, Difference)) + geom_vline(xintercept = floor(yday(cd) / 7), size = .1) + scale_x_continuous(&quot;Week of year&quot;, breaks = pretty_breaks()) + scale_y_continuous( &quot;Difference\\n(2020 - 2019)&quot;, breaks = pretty_breaks(), labels = function(x) str_glue(&quot;{x/1e6}M&quot;) ) + geom_hline(lty = 2, yintercept = 0, size = .2) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .2) + geom_line() + facet_wrap(&quot;MP&quot;, scales = &quot;free&quot;, nrow = 2) + theme(legend.position = &quot;none&quot;) ((p1 + theme(axis.title.x = element_blank())) / p2) + plot_layout(heights = c(.4, .6), guides = &quot;collect&quot;) &amp; theme(legend.position = &quot;none&quot;) ggsave(&quot;Figure2-mp-brms.png&quot;, width = 8, height = 6) "]
]
